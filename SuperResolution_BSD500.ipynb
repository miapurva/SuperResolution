{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SuperResolution_BSD500.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-viHNnpkjU-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf models;\n",
        "!mkdir models;\n",
        "import torch.utils.data as data\n",
        "\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
        "\n",
        "\n",
        "def load_img(filepath):\n",
        "    img = Image.open(filepath).convert('YCbCr')\n",
        "    y, _, _ = img.split()\n",
        "    return y\n",
        "\n",
        "\n",
        "class DatasetFromFolder(data.Dataset):\n",
        "    def __init__(self, image_dir, input_transform=None, target_transform=None):\n",
        "        super(DatasetFromFolder, self).__init__()\n",
        "        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n",
        "\n",
        "        self.input_transform = input_transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input = load_img(self.image_filenames[index])\n",
        "        target = input.copy()\n",
        "        if self.input_transform:\n",
        "            input = self.input_transform(input)\n",
        "        if self.target_transform:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return input, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQl-JxYKaoQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os.path import exists, join, basename\n",
        "from os import makedirs, remove\n",
        "from six.moves import urllib\n",
        "import tarfile\n",
        "from torchvision.transforms import Compose, CenterCrop, ToTensor, Resize\n",
        "\n",
        "\n",
        "\n",
        "def download_bsd300(dest=\"dataset1\"):\n",
        "    output_image_dir = join(dest, \"BSR/BSDS500/data/images\")\n",
        "\n",
        "    if not exists(output_image_dir):\n",
        "        makedirs(dest)\n",
        "        # url=\"drive/My Drive/BSR_bsds500.tgz\"\n",
        "        url = \"http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz\"\n",
        "        print(\"downloading data \", url)\n",
        "\n",
        "        data = urllib.request.urlopen(url)\n",
        "        # file_path = join(dest,data)\n",
        "        file_path = join(dest, basename(url))\n",
        "        with open(file_path, 'wb') as f:\n",
        "            f.write(data.read())\n",
        "\n",
        "        print(\"Extracting data\")\n",
        "        with tarfile.open(file_path) as tar:\n",
        "            for item in tar:\n",
        "                tar.extract(item, dest)\n",
        "\n",
        "        remove(file_path)\n",
        "\n",
        "    return output_image_dir\n",
        "\n",
        "#get image in the multiple of upscale factor\n",
        "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
        "    return crop_size - (crop_size % upscale_factor)\n",
        "\n",
        "#downscaling the image\n",
        "def input_transform(crop_size, upscale_factor):\n",
        "    return Compose([\n",
        "        CenterCrop(crop_size),\n",
        "        Resize(crop_size // upscale_factor),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "\n",
        "\n",
        "def target_transform(crop_size):\n",
        "    return Compose([\n",
        "        CenterCrop(crop_size),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "\n",
        "\n",
        "def get_training_set(upscale_factor):\n",
        "    root_dir = download_bsd300()\n",
        "    train_dir = join(root_dir, \"train\")\n",
        "    crop_size = calculate_valid_crop_size(256, upscale_factor)\n",
        "\n",
        "    return DatasetFromFolder(train_dir,\n",
        "                             input_transform=input_transform(crop_size, upscale_factor),\n",
        "                             target_transform=target_transform(crop_size))\n",
        "\n",
        "\n",
        "def get_test_set(upscale_factor):\n",
        "    root_dir = download_bsd300()\n",
        "    test_dir = join(root_dir, \"test\")\n",
        "    crop_size = calculate_valid_crop_size(256, upscale_factor)\n",
        "\n",
        "    return DatasetFromFolder(test_dir,\n",
        "                             input_transform=input_transform(crop_size, upscale_factor),\n",
        "                             target_transform=target_transform(crop_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umJ-4JFhjsc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, upscale_factor):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        # x = self.relu(self.conv4(x))\n",
        "        x = self.pixel_shuffle(self.conv4(x))\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
        "        # init.orthogonal_(self.conv4.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv4.weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiIQg70V9Sgc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "93f037e7-7284-4be3-b440-742444630b59"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from math import log10\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "upscale_factor = 3\n",
        "threads = 6\n",
        "batchSize = 4\n",
        "testBatchSize = 100\n",
        "nEpochs = 500\n",
        "lr = 0.001\n",
        "\n",
        "print('===> Loading datasets')\n",
        "train_set = get_training_set(upscale_factor)\n",
        "test_set = get_test_set(upscale_factor)\n",
        "training_data_loader = DataLoader(dataset=train_set, num_workers=threads, batch_size=batchSize, shuffle=True)\n",
        "testing_data_loader = DataLoader(dataset=test_set, num_workers=threads, batch_size=testBatchSize, shuffle=False)\n",
        "\n",
        "print('===> Building model')\n",
        "model = Net(upscale_factor=upscale_factor).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# sched = optim.lr_scheduler.StepLR(optimizer,10, gamma=0.1, last_epoch=-1)\n",
        "\n",
        "def train(epoch):\n",
        "    epoch_loss = 0\n",
        "    for iteration, batch in enumerate(training_data_loader, 1):\n",
        "        input, target = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(input), target)\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(training_data_loader), loss.item()))\n",
        "\n",
        "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n",
        "\n",
        "count=0\n",
        "def test():\n",
        "    avg_psnr = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in testing_data_loader:\n",
        "            input, target = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "            prediction = model(input)\n",
        "            mse = criterion(prediction, target)\n",
        "            psnr = 10 * log10(1 / mse.item())\n",
        "            avg_psnr += psnr\n",
        "           \n",
        "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(testing_data_loader)))\n",
        "    \n",
        "    return avg_psnr\n",
        "    # max_psnr=avg_psnr\n",
        "    # count=1\n",
        "    # if max_psnr>=avg_psnr and count==1:\n",
        "    #     checkpoint(epoch)\n",
        "\n",
        "\n",
        "def checkpoint(epoch):\n",
        "    model_out_path = \"models/model_best.pth\"\n",
        "    torch.save(model, model_out_path)\n",
        "    \n",
        "    print(\"Checkpoint saved to {}\".format(model_out_path))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===> Loading datasets\n",
            "downloading data  http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz\n",
            "Extracting data\n",
            "===> Building model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SESZ9Nbeju3B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72c2c377-e77e-4283-a679-7dc603cb1c38"
      },
      "source": [
        "maxpsnr = 24.9444\n",
        "for epoch in range(1, nEpochs + 1):\n",
        "    train(epoch)\n",
        "    psnr = test()\n",
        "    # sched.step()\n",
        "    if psnr > maxpsnr:\n",
        "        maxpsnr = psnr\n",
        "        checkpoint(epoch)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===> Epoch 1 Complete: Avg. Loss: 0.0310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK59qmjvdpsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToTensor\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "# Training settings\n",
        "# parser = argparse.ArgumentParser(description='PyTorch Super Res Example')\n",
        "# parser.add_argument('--input_image', type=str, required=True, help='input image to use')\n",
        "# parser.add_argument('--model', type=str, required=True, help='model file to use')\n",
        "# parser.add_argument('--output_filename', type=str, help='where to save the output image')\n",
        "# parser.add_argument('--cuda', action='store_true', help='use cuda')\n",
        "# opt = parser.parse_args()\n",
        "a=time.time()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# input_image=\"dataset/BSDS300/images/test/101085.jpg\"\n",
        "input_image=\"c1.jpg\"\n",
        "model=\"models/model_best.pth\"\n",
        "# output_filename = \"output.png\"\n",
        "for i in range(0,100):\n",
        "    if(not os.path.exists (\"out\"+str(i)+'.png')):\n",
        "        output_filename= \"out\"+str(i)+'.png'\n",
        "        break\n",
        "\n",
        "img = Image.open(input_image).convert('YCbCr')\n",
        "y, cb, cr = img.split()\n",
        "\n",
        "model = torch.load(model)\n",
        "img_to_tensor = ToTensor()\n",
        "input = img_to_tensor(y).view(1, -1, y.size[1], y.size[0])\n",
        "\n",
        "out = model(input.to(device))\n",
        "out = out.cpu()\n",
        "out_img_y = out[0].detach().numpy()\n",
        "out_img_y *= 255.0\n",
        "out_img_y = out_img_y.clip(0, 255)\n",
        "out_img_y = Image.fromarray(np.uint8(out_img_y[0]), mode='L')\n",
        "\n",
        "out_img_cb = cb.resize(out_img_y.size, Image.BICUBIC)\n",
        "out_img_cr = cr.resize(out_img_y.size, Image.BICUBIC)\n",
        "out_img = Image.merge('YCbCr', [out_img_y, out_img_cb, out_img_cr]).convert('RGB')\n",
        "\n",
        "out_img.save(output_filename)\n",
        "b=time.time()\n",
        "print('output image saved to ', output_filename)\n",
        "print('Total time',b-a)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}